<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Emotion Detector with Loading Progress</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      text-align: center;
      margin: 30px;
    }
    #progress {
      font-weight: bold;
      margin: 10px 0;
    }
    canvas {
      margin-top: 20px;
    }
  </style>
</head>
<body>

  <h2>Facial Emotion Detector</h2>
  <input type="file" id="imageUpload" accept="image/*" />
  <div id="progress">Loading models: 0%</div>
  <div id="result"></div>
  <canvas id="canvas"></canvas>

  <!-- Load face-api.js library -->
  <script src="https://cdn.jsdelivr.net/npm/face-api.js"></script>

  <script>
    const progress = document.getElementById('progress');
    const result = document.getElementById('result');
    const imageUpload = document.getElementById('imageUpload');
    const canvas = document.getElementById('canvas');

    // Load models with progress simulation
    async function loadModels() {
      let loaded = 0;
      const total = 2;

      function updateProgress() {
        const percent = Math.round((loaded / total) * 100);
        progress.textContent = `Loading models: ${percent}%`;
      }

      await faceapi.nets.tinyFaceDetector.loadFromUri('https://ganeshgoudkota.github.io/emotion-detector/models');
      loaded++; updateProgress();

      await faceapi.nets.faceExpressionNet.loadFromUri('https://ganeshgoudkota.github.io/emotion-detector/models');
      loaded++; updateProgress();

      progress.textContent = "Models loaded! Upload a face image.";
    }

    loadModels().catch(err => {
      progress.textContent = "Error loading models.";
      console.error(err);
    });

    imageUpload.addEventListener('change', async () => {
      const file = imageUpload.files[0];
      if (!file) return;

      result.textContent = "Detecting...";

      const image = await faceapi.bufferToImage(file);
      canvas.width = image.width;
      canvas.height = image.height;
      const ctx = canvas.getContext('2d');
      ctx.clearRect(0, 0, canvas.width, canvas.height);
      ctx.drawImage(image, 0, 0);

      const detections = await faceapi
        .detectAllFaces(image, new faceapi.TinyFaceDetectorOptions())
        .withFaceExpressions();

      if (detections.length === 0) {
        result.textContent = "No face detected.";
      } else {
        result.textContent = "Emotions detected.";
        faceapi.draw.drawDetections(canvas, detections);
        faceapi.draw.drawFaceExpressions(canvas, detections);
      }
    });
  </script>

</body>
</html>
