<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Emotion Detector with Progress</title>
  <style>
    body { font-family: Arial; text-align: center; margin: 20px; }
    #progress { font-weight: bold; margin-bottom: 10px; }
    canvas { margin-top: 10px; }
  </style>
</head>
<body>
  <h2>Facial Emotion Detector</h2>
  <input type="file" id="imageUpload" accept="image/*" />
  <div id="progress">Loading models: 0%</div>
  <div id="result"></div>
  <canvas id="canvas"></canvas>

  <script defer src="https://cdn.jsdelivr.net/npm/face-api.js"></script>
  <script>
    const imageUpload = document.getElementById('imageUpload');
    const result = document.getElementById('result');
    const canvas = document.getElementById('canvas');
    const progress = document.getElementById('progress');

    async function loadModelsWithProgress() {
      const modelUrls = [
        'https://ganeshgoudkota.github.io/emotion-detector/models/tiny_face_detector_model-weights_manifest.json',
        'https://ganeshgoudkota.github.io/emotion-detector/models/face_expression_model-weights_manifest.json'
      ];
      const total = modelUrls.length;
      let loaded = 0;

      function updateProgress() {
        const percent = Math.round((loaded / total) * 100);
        progress.textContent = `Loading models: ${percent}%`;
      }

      // Load tinyFaceDetector
      await faceapi.nets.tinyFaceDetector.loadFromUri('https://ganeshgoudkota.github.io/emotion-detector/models');
      loaded++;
      updateProgress();

      // Load faceExpressionNet
      await faceapi.nets.faceExpressionNet.loadFromUri('https://ganeshgoudkota.github.io/emotion-detector/models');
      loaded++;
      updateProgress();
    }

    loadModelsWithProgress().then(() => {
      progress.textContent = "Models loaded! Upload a face image.";
    }).catch(err => {
      progress.textContent = "Error loading models: " + err;
      console.error(err);
    });

    imageUpload.addEventListener('change', async () => {
      if (!imageUpload.files.length) return;

      result.textContent = "Detecting...";

      const img = await faceapi.bufferToImage(imageUpload.files[0]);

      canvas.width = img.width;
      canvas.height = img.height;

      const ctx = canvas.getContext('2d');
      ctx.clearRect(0, 0, canvas.width, canvas.height);
      ctx.drawImage(img, 0, 0);

      const detections = await faceapi.detectAllFaces(img, new faceapi.TinyFaceDetectorOptions()).withFaceExpressions();

      if (detections.length === 0) {
        result.textContent = "No face detected.";
      } else {
        result.textContent = "Emotions detected.";
        faceapi.draw.drawDetections(canvas, detections);
        faceapi.draw.drawFaceExpressions(canvas, detections);
      }
    });
  </script>
</body>
</html>
